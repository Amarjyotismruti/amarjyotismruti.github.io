<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>A reflection of my thoughts and experiments on the fascinating realm of Robotics and Artificial Intelligence.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 14 Dec 2017 04:19:29 -0500</pubDate>
    <lastBuildDate>Thu, 14 Dec 2017 04:19:29 -0500</lastBuildDate>
    <generator>Jekyll v3.6.2</generator>
    
      <item>
        <title>Nonlinear Dimensionality Reduction by Locally Linear Embedding</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;http://www.robots.ox.ac.uk/~az/lectures/ml/lle.pdf&quot;&gt;Roweis, Saul, 2000&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;ISOMAP and MDS require estimates of pairwise distances between data points. LLE gets around this by “thinking” globally but fitting locally. Essentially, each data point should hypothetically be representable by a locally linear patch. Therefore, LLE seeks $W$ such that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(W) = \sum_i \| X_i - \sum_j W_{ij} X_j \|^{2}&lt;/script&gt;

&lt;p&gt;is minimized. Hence, a data point should be reconstructed by its neighbors; the problem is solved via least squares. Note that the weights are invariant to affine transformations and translations. Assuming that $W$ should be preserved in a lower dimensional representation of the data, LLE seeks to solve&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi (Y) = \sum_i \| Y_i - \sum_j W_{ij} Y_j \|^{2}&lt;/script&gt;

&lt;p&gt;The optimal coordinates $Y$ can be found by solving a sparse $n \times n$ eigenvalue problem.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Because of the simple construction and use of simple linear algebra, LLE has better theoretical properties than other algorithms like autoencoders&lt;/li&gt;
  &lt;li&gt;It also has less hyperparameters&lt;/li&gt;
  &lt;li&gt;Doesn’t need to be rerun when new dimensions are added to the embedding space (old ones do not change)&lt;/li&gt;
  &lt;li&gt;Does LLE work on spheres? It seems like it would run into the same problem if the sphere didn’t have a hole taken out of it&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 14 Sep 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/general-ml/2017/09/14/LLE.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/general-ml/2017/09/14/LLE.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>general-ML</category>
        
      </item>
    
      <item>
        <title>A Global Geometric Framework for Nonlinear Dimensionality Reduction</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;http://www.jstor.org/stable/pdf/3081721.pdf&quot;&gt;Tenenbaum, et. al. 2000&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Isomap, seemingly named for “Isometric mapping”, seeks to provide a solution to the problem of non-linear dimensionality reduction. The method is especially suitable for high-dimensional manifolds that exhibit non-Euclidean geometry, such that the Euclidean distance between data points returns distances that are not actually realistic for the underlying low-dimensional manifold. The intuition for this approach lies in the use of the all-pairs shortest path algorithm to improve upon Multi-dimensional scaling. Under general conditions on the density and curvature of the points, a geodesic distance can be estimated between far away points on the high-dimensional manifold via the all-pairs shortest path that converges to the true distance in the limit. Then, similar to MDS, Isomap attempts to find coordinate vectors for a low-dimensional space within which the distances between points are preserved as much as possible. This essentially results in the selection of the largest p eigenvectors of the matrix of estimated distances on the high-dimensional manifold (transformed to inner products). To make the algorithm work, the first step consists of clustering the data points either using k-NN or $\epsilon$-balls. Edges are placed between all points clustered together, to form the graph upon which all-pairs shortest path is run.&lt;/p&gt;

&lt;p&gt;In this paper, the authors present examples of applying Isomap to a dataset of faces, MNIST, and the “swiss roll” dataset. Interestingly, they are able to map the faces dataset to a 3-D space, capturing left-right poses, up-down poses, and variations in ambient lighting. They show that PCA and MDS converge (the residual loss goes to 0) but they are unable to recover the true dimensionality of the low-dimensional manifold. This seems to be troublesome, because if one naively applies PCA to a dataset and the residual loss goes to 0, it appears then that the user of this algorithm will mistakenly believe they have recovered the true low-dimensional manifold. It would be interesting to then run a classifier on this low-dimensional representation produced by PCA, and then check the performance against the same classifier using the low-dimensional representation learned by Isomap. I imagine that the Isomap classifier will have slightly better performance.&lt;/p&gt;

</description>
        <pubDate>Thu, 31 Aug 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/general-ml/2017/08/31/ISOMAP.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/general-ml/2017/08/31/ISOMAP.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>general-ML</category>
        
      </item>
    
      <item>
        <title>Towards Deep Symbolic Reinforcement Learning</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1609.05518v2&quot;&gt;Garnelo, et. al., 2017&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;div&gt;
	&lt;div class=&quot;image-wrapper&quot;&gt;
	
	&lt;img src=&quot;/img/symbolic-rl.bmp&quot; alt=&quot;&quot; width=&quot;&quot; height=&quot;&quot; /&gt;
	
	&lt;/div&gt;
	&lt;div&gt;
	
	&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;It is desirable for an agent to symbolically reason about its environment, in order to expediate the process of learning optimal behaviors. However, “classic” symbolic AI suffers from the &lt;strong&gt;symbol grounding problem&lt;/strong&gt;; symbolic elements have traditionally been hand-crafted, and hence, are brittle. On the other hand, Deep Learning can be used to automatically learn ~optimal “symbols”, upon which a reinforcement learning agent could learn behaviors motivated by these learned symbols. By forcing a Deep RL agent to operate in a symbolic domain, the decisions made by the agent are naturally more interpretable.&lt;/p&gt;

&lt;p&gt;The aspects of AI that this work focuses on are closely related to those proposed in the manifesto written by &lt;a href=&quot;http://pemami4911.github.io/paper-summaries/general-ai/2016/05/13/learning-to-think.html&quot;&gt;Lake et. al.&lt;/a&gt;. There are also nods to &lt;a href=&quot;http://cogs.indiana.edu/people/profile.php?u=dughof&quot;&gt;Douglas Hofstadter’s&lt;/a&gt; work on analogy as being the main driving force behind intelligence, as well as &lt;a href=&quot;http://www.hutter1.net/&quot;&gt;Marcus Hutter’s&lt;/a&gt; Universal Artificial Intelligence work.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Conceptual abstraction - agents can use abstractions to make analogies and hence learn optimal behaviors faster&lt;/li&gt;
  &lt;li&gt;Compositional structure - probabilistic first-order logic provides the underlying framework for a representation medium that is compositional&lt;/li&gt;
  &lt;li&gt;Common sense priors - priors from simple object tracking! Persistence, kinematics (constant velocity models), etc.&lt;/li&gt;
  &lt;li&gt;Causal reasoning - the proposed architecture attempts to discover causal structure in the environment to accelerate learning by explicitly maintaining sets of causal rules&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A Q-learning agent is designed for their toy example. The state space consists of the different interactions between the learned symbolic abstractions of the environment. A tracking process is carried out separately from the agent for keeping track of the different symbolic abstractions.&lt;/p&gt;

&lt;p&gt;Main result: on random toy problem instances, DQN is not able to better than chance… Hypothesis: DQN relies on the fact that you should be able to internally learn a model for $p(s_{t+1}|s_{t},a_{t})$ after going through a lot of examples. When this distribution is non-stationary, it can’t! However, the proposed architecture doesn’t seem to care about this. It instead directly is learning about object interactions.&lt;/p&gt;

&lt;h3 id=&quot;methodology&quot;&gt;Methodology&lt;/h3&gt;

&lt;p&gt;Their environment is a simple B&amp;amp;W grid upon which shapes (O’s, X’s, and +’s) can be randomly positioned.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Low-level symbol generation: Uses a convolutional autoencoder to do simple dimensionality reduction and learn relevant features. Then, they do a form of unsupervised clustering by finding the maximally activated feature corresponding to each pixel, then thresholding these values. Once they have a sparse list of salient pixels, they form a spectrum with the activations across all features, and define a distance metric on the spectra via the sum of squared distances. This allows them to cluster pixels (objects) into certain categories.&lt;/li&gt;
  &lt;li&gt;Representation building: notions of spatial proximity, type-transitions between frames (including birth and death), neighborhood (number of neighbors), relative distances and positions&lt;/li&gt;
  &lt;li&gt;Reinforcement Learning: Agent is the ‘+’, separate Q for interactions between different pairs of object types. State space describes different possible relations between two objects types. Seek to learn how to interact via (U, D, L, R) actions.&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Tue, 29 Aug 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/reinforcement-learning-theory/2017/08/29/deep-symbolic-rl.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/reinforcement-learning-theory/2017/08/29/deep-symbolic-rl.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>reinforcement-learning-theory</category>
        
      </item>
    
      <item>
        <title>Deep Learning via Hessian-Free Optimization</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf&quot;&gt;James Martens, 2010&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This paper introduces a fairly complex optimization algorithm for deep nets that uses approximate 2nd-order gradient information&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In Hessian-Free optimization, you can directly approximate a Hessian-vector product $Hv$ with the method of finite-differences; this only costs 1 more gradient evaluation&lt;/li&gt;
  &lt;li&gt;linear conjugate gradient algorithm allows one to solve for the optimal search direction in $O(N)$ iterations ($N$ is the number of parameters) with only matrix-vector products&lt;/li&gt;
  &lt;li&gt;Newton’s method is scale invariant, e.g., for a new parameterization $\hat{\theta} = A \theta$ for some invertible matrix $A$, the optimal search direction is now $\hat{p} = A p$ where $p$ is the original optimal search direction. Gradient descent is not (need proof!) - so many bad things about GD, but it’s so easy to implement..&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;considerations-when-applying-this-technique&quot;&gt;Considerations when applying this technique&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Need to use an adaptive damping parameters $\lambda$ beause the relative scale of $B = H(\theta)$ is changing and $H(\theta)$ must remain positive semidefinite. Recommended heuristic is given in Section 4.1&lt;/li&gt;
  &lt;li&gt;Gauss-Newton matrix $G$ can produce better search directions than $H$, see &lt;a href=&quot;http://andrew.gibiansky.com/blog/machine-learning/gauss-newton-matrix/&quot;&gt;this blog post&lt;/a&gt; for a summary&lt;/li&gt;
  &lt;li&gt;Compute gradient on entire dataset, but use minibatches to compute Hessian-vector products. SGD requires 10’s of thousands of iterations versus ~200 for HF&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 07 Aug 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/deep-learning/2017/08/07/deep-hessian-free.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/deep-learning/2017/08/07/deep-hessian-free.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>deep-learning</category>
        
      </item>
    
      <item>
        <title>The Markov Chain Monte Carlo Revolution</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ams.org/journals/bull/2009-46-02/S0273-0979-08-01238-X/home.html&quot;&gt;Persi Diaconis, 2009&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-fundamental-theorem-of-markov-chains&quot;&gt;The Fundamental Theorem of Markov Chains&lt;/h3&gt;

&lt;p&gt;From any starting state $x$, the $n^{th}$ step of a run of the MC has chance close to $\pi (y)$ of being at $y$ if $n$ is large. The MC must be connected, i.e., in the limit, the kernel $K$/proposal distribution/Markov transition matrix has no zero-probability transitions.&lt;/p&gt;

&lt;h2 id=&quot;metropolis-algorithm&quot;&gt;Metropolis Algorithm&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Based on “proposal” and “acceptance”&lt;/li&gt;
  &lt;li&gt;The acceptance ratio is to ensure that the fraction of time spent in each state is proportional to $\pi(x)$ for $x \in \chi$&lt;/li&gt;
  &lt;li&gt;In this algorithm, the normalization constants of the stationary distributions cancel out!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In Equation 2.3, if the acceptance ratio is $&amp;lt; 1$, you are multiplying the probabilities $J(x,y)$ and $A(x,y)$ together. This generates the success probability $J(x,y)A(x,y)$ for transitioning x -&amp;gt; y. You want to accept transitions that move to states that are reversible (and hence move you closer to the true stationary distribution), and stay away from states that are not. The algorithm hence allows the Markov Chain to stay in the same place with some probability if the acceptance ratio is low.&lt;/p&gt;

&lt;p&gt;This algorithm produces a reversible Markov chain:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi(x) K(x,y) = \pi(y) K(y, x).&lt;/script&gt;

&lt;p&gt;Since $\pi K = \pi$ (the stationary distribution is unchanged by the operation of the kernel $K$), $\pi$ is a left eigenvector of $K$ with eigenvalue 1. The basic result on convergence to the stationary distribution can be found by taking the spectral decomposition of $K$.&lt;/p&gt;

&lt;h2 id=&quot;gibbs-sampler&quot;&gt;Gibbs sampler&lt;/h2&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.nehalemlabs.net/prototype/blog/2014/02/24/an-introduction-to-the-metropolis-method-with-python/&quot;&gt;Here’s a neat example of the Metropolis Hastings algorithm for sampling from a boltzmann distribution&lt;/a&gt;. Remember- low-energy states have high boltzmann probability!&lt;/p&gt;
</description>
        <pubDate>Wed, 21 Jun 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/general-ml/2017/06/21/mcmc-rev.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/general-ml/2017/06/21/mcmc-rev.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>general-ML</category>
        
      </item>
    
      <item>
        <title>Recurrent Environment Simulators</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.02254&quot;&gt;Chiappa, et. al., 2017&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This paper extends the results on action-conditional video prediction from &lt;a href=&quot;https://arxiv.org/abs/1507.08750&quot;&gt;Oh, et. al., 2015&lt;/a&gt;. The motivation behind this line of research is to investigate whether training RL agents to learn how their actions affect the environment reduces the amount of time they spend in exploration. The authors outline the following main challenges:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The properties of generalization and sensitivity to model structure of these methods are poorly understood&lt;/li&gt;
  &lt;li&gt;Accurate prediction for long time periods into the future is hard&lt;/li&gt;
  &lt;li&gt;Models that predict the high-dim image directly each time an action is taken are inefficient&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The general approach is to use a Conv-RNN to take an observation from the environment and produce a high-dim state representation. This high-dim state representation can be combined with the action taken by the agent to predict how the environment will change. In other words, the goal is to learn a parametric model that approximates the state-action transition.&lt;/p&gt;

&lt;p&gt;One of the main contributions of this work is fusing the action with the hidden state representation when predicting the next hidden state representation in time. In previous work, the action was used instead to directly predict the next image. Why? Authors suggest it could “enable the model to incorporate action information more effectively”.&lt;/p&gt;

&lt;p&gt;Using observations directly from the environment to predict the next hidden state representation forces the agent to make predictions only when the next frame is available, i.e., 1-step prediction. Rolling forward the agent’s own predictions in the future allows it to predict many time steps ahead in a more efficient manner.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prediction-dependent transitions&lt;/strong&gt; are ones of the form &lt;script type=&quot;math/tex&quot;&gt;s_t = f(s_{t-1}, a_{t-1}, C(\mathbb{I}(\hat x_{t-1}, x_{t-1})))&lt;/script&gt; where $s_t$ is the hidden state representation.&lt;/p&gt;

&lt;p&gt;There’s a trade-off between short- and long-term accuracy and prediction- vs observation-dependent transitions. When prediction-dependent transitions are mostly used, the agent learns better global dynamics of the game and can do better with long-term accuracy. When observation-dependent transitions are mixed with prediction-dependent, the agent pays more attention to details that provide it with better short-term accuracy.&lt;/p&gt;

&lt;p&gt;They evaluated their model on Breakout, Freeway, and Pong by replacing the real game with the learned environment simulator. A human would “play” the game, and the learned simulator would return the next frame given the action input by the human.&lt;/p&gt;

&lt;h2 id=&quot;related-works&quot;&gt;Related works&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5859-action-conditional-video-prediction-using-deep-networks-in-atari-games&quot;&gt;Action-conditional Video Prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.05397.pdf&quot;&gt;UNREAL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.acolyer.org/2017/05/12/learning-to-act-by-predicting-the-future/&quot;&gt;Learning to Act By Predicting the Future&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Wed, 31 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/deep-rl/2017/05/31/recurrent-environment-simulators.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/deep-rl/2017/05/31/recurrent-environment-simulators.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>deep-RL</category>
        
      </item>
    
      <item>
        <title>Interaction Networks for Learning about Objects, Relations, and Physics</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1612.00222&quot;&gt;Battaglia, et. al., 2016&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This ambitious paper proposes a deep learning framework for modeling the physical interactions between objects in an environment. The authors present Interaction Networks (IN), which explicitly separate the processes of learning object dynamics and relations between objects.&lt;/p&gt;

&lt;p&gt;IN is designed to work on graphs where objects are nodes and edges are relations between objects. This is to make it scalable to different environments.&lt;/p&gt;

&lt;p&gt;The architecture is simple; two MLPs learn representations over object dynamics and relations between objects, respectively. The input to the system is the state decomposed into the objects and their physical relations (gravitational attraciton, collisions, springs), as well as external effects (gravity). Object states can be further decomposed into position and velocity. In general, the output is the velocity of the objects at the subsequent time step.&lt;/p&gt;

&lt;p&gt;The system is evaluated on interesting physical reasoning tasks, such as n-bodies interacting, bouncing balls colliding, and string/mass systems. IN showed significantly lower MSE when predicting future states of objects in the scenes compared to simple baselines.&lt;/p&gt;

&lt;p&gt;A custom physics engine was used to generate trajectories for training data. All training objectives and test measures used MSE between the model’s predictions and the ground truth target.&lt;/p&gt;
</description>
        <pubDate>Sun, 14 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/deep-learning/2017/05/14/interaction-networks-for-learning-about-objects-relations-physics.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/deep-learning/2017/05/14/interaction-networks-for-learning-about-objects-relations-physics.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>deep-learning</category>
        
      </item>
    
      <item>
        <title>DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.04394v1&quot;&gt;Lee, et. al., 2016&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This paper presents a framework for predicting how a scene containing multiple interacting agents will play out by leveraging a number of powerful techniques. DESIRE stands for Deep Stochastic IOC RNN Encoder-decoder framework.&lt;/p&gt;

&lt;p&gt;The following are the biggest obstacles for successfully predicting future actions taken by interacting agents given a visual snapshot of the present:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The space of future states for each agent in a scene is hard to optimize over; even when taking the context of the scene into account, there could be many plausible outcomes that seem equally likely&lt;/li&gt;
  &lt;li&gt;In turn, this makes rolling out and scoring potential future trajectories computationally expensive, since it requires sampling a large number of trajectories. This isn’t relevant for offline processing, but for real-time robotics applications, this is important&lt;/li&gt;
  &lt;li&gt;The multi-agent problem; how to infer interactions between multiple actors in a scene?&lt;/li&gt;
  &lt;li&gt;Taking into account long-term prediction rewards, rather than just one-step prediction&lt;/li&gt;
  &lt;li&gt;How to define a multi-objective loss function that doesn’t commit errors such as averaging over all future possibilities&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DESIRE attempts to address these challenges as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Diverse sample generation using a conditional Variational Autoencoder. This allows for differentiable efficient sampling of plausible futures&lt;/li&gt;
  &lt;li&gt;RNN encoder-decoder neural architecture that allows for mapping trajectories represented by world coordinates in $\mathbb{R}^2$ or $\mathbb{R}^3$ to a high-dimensional distributed representation that can be efficiently combined with the Conditoinal VAE&lt;/li&gt;
  &lt;li&gt;An Inverse Optimal-Control (IOC) based Ranking and Refinement module that determines the most likely hypotheses, while incorporating scene context and interactions. The IOC module estimates a regression vector to refine each prediction sample.&lt;/li&gt;
  &lt;li&gt;A convolutional neural network is used to carry out scene context fusion. This enables encoding features such as object velocities into the hypothesis scoring component.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The model is trained end-to-end with a total loss consisting of multiple auxiliary losses (e.g., reconstruction error from the output trajectory of the decoder during training). The authors evaluate its performance on the KITTI and Stanford Drone tracking datasets. They show the performance with the metric “error in meters” for future time steps at intervals of 1, 2, 3, and 4 seconds.&lt;/p&gt;

&lt;p&gt;Overall, the proposed model seems quite complex, with many sub-components. However, the motivation behind each component is reasonable and the model is shown to perform well on the datasets. The separation of the system into a Sample Generation Module and the Ranking and Refinement Module is reminiscent of the actor-critic architecture in RL. However, the Ranking and Refinement Module isn’t handed a reward function like the critic usually is; rather, it uses unsupervised learning losses to learn to score/refine the “actor”, or Sample Generation Module.&lt;/p&gt;
</description>
        <pubDate>Sun, 14 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/deep-learning/2017/05/14/DESIRE.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/deep-learning/2017/05/14/DESIRE.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>deep-learning</category>
        
      </item>
    
      <item>
        <title>Fast, Exact, and Multi-Scale Inference for Semantic Image Segmentation with Deep Gaussian CRFs</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.08358&quot;&gt;Chandra, Kokkinos, 2016&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;semantic-image-segmentation&quot;&gt;Semantic Image Segmentation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://wiki.tum.de/download/attachments/23561833/sms.png?version=1&amp;amp;modificationDate=1483619907233&amp;amp;api=v2&quot;&gt;Image Example&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Put simply, the task is to cluster pixels in an image together and to assign all pixels in a cluster a meaningful label. Labels are generally “high-level” concepts, such as “horse”, “dog”, “boat”, etc.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://host.robots.ox.ac.uk/pascal/VOC/voc2012/&quot;&gt;Here is the VOC PASCAL 2012&lt;/a&gt; dataset used in this paper.&lt;/p&gt;

&lt;h2 id=&quot;discussion-qs&quot;&gt;Discussion Q’s&lt;/h2&gt;

&lt;h2 id=&quot;why-g-crfs&quot;&gt;Why G-CRFs?&lt;/h2&gt;

&lt;p&gt;Joint distributions are hard, so exploit factorizable (exponential-family) probability distributions and conditional independence. This results in a graph-like structure.&lt;/p&gt;

&lt;p&gt;If the label assigned to each pixel is a random variable, then an conditional random field suggests that there’s a dependence between a pixel’s label and the label’s of other nearby pixels. This seems intuitive.&lt;/p&gt;

&lt;p&gt;Author’s argue that continuous Gaussian outputs are unimodal conditioned on the data, so given an image, one solution dominates the posterior. The log-likelihood is a quadratic, which allows the approximate inference task to be cast a quadratic optimization in an energy-minimization setting.&lt;/p&gt;

&lt;h2 id=&quot;deep-g-crf-architecture&quot;&gt;Deep G-CRF architecture&lt;/h2&gt;

&lt;p&gt;The basic idea is to set the outputs of a convolutional neural network to be the energy of a segmentation hypothesis, in the form of 
&lt;script type=&quot;math/tex&quot;&gt;\begin{equation}
E(x) = \frac{1}{2} x^{\intercal}(A + \lambda I) x - Bx
\end{equation}&lt;/script&gt; 
. The network predicts what the $A$ (pairwise) and $B$ (unary) terms in the energy function are for an image. $\lambda$ is set manually to enforce positive-definiteness. Then a Quadratic Optimization + softmax module gives the final per-class scores for each pixel in the image (See Fig. 1) by solving for $x$. Originally, $A$ is a $(P \times L) \times (P \times L)$ matrix, where $L$ is the number of class labels and $P$ is number of pixels.&lt;/p&gt;

&lt;h2 id=&quot;shared-pair-wise-terms&quot;&gt;Shared pair-wise terms&lt;/h2&gt;

&lt;p&gt;$A$ is no longer dependent on the number of class labels; only care about pixel interactions independent on what the label is. Now, the inference equation $(A + \lambda I) x = B$ is reduced to a system of $L + 1$ equations for $A$ of dim $P \times P$.&lt;/p&gt;

&lt;h2 id=&quot;conjugate-gradient-method&quot;&gt;Conjugate Gradient method&lt;/h2&gt;

&lt;p&gt;Need to solve $x = A^{-1}b$. 
The $A$ matrix is very sparse, since it only deals with 4, 8, or 12-connected neighborhoods. CG is the current recommended approach for solving $Ax = b$ when $A$ is sparse &lt;a href=&quot;https://math.stackexchange.com/questions/655306/conjugate-gradient-method-and-sparse-systems&quot;&gt;why?&lt;/a&gt; When $A$ is dense, it is recommended to factorize A and then use backsubstitution. &lt;a href=&quot;https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf&quot;&gt;see here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;Try out the above + fusing information across 3 different resolutions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;metric - Intersection over Union&lt;/li&gt;
  &lt;li&gt;baselines - Multiresolution DeepLab-LargeFOV, CRF-RNN&lt;/li&gt;
  &lt;li&gt;QO network - Baseline extended to have a binary and unary stream. QO module can be shared by all resolutions, or replicated three times for each scale&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;75.5% mean IOU on VOC PASCAL 2012 for this approach. Without more details and tests of significance, hard to say whether this method is really more effective than prev SOTA. It seems to do about ~1-2% IOU better than the baselines. Also seems to be much faster.&lt;/p&gt;
</description>
        <pubDate>Thu, 04 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/computer-vision/2017/05/04/semantic-image-seg-with-deep-g-crfs.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/computer-vision/2017/05/04/semantic-image-seg-with-deep-g-crfs.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>computer-vision</category>
        
      </item>
    
      <item>
        <title>Topology and Data</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ams.org/images/carlsson-notes.pdf&quot;&gt;Gunnar Carlsson, 2009&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;definitions&quot;&gt;Definitions&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Homology&lt;/strong&gt; is a general way of associating a sequence of algebraic objects such as abelian groups or modules to other mathematical objects such as topological spaces. Homology itself was developed as a way to analyse and classify manifolds according to their cycles – closed loops (or more generally submanifolds) that can be drawn on a given n dimensional manifold but not continuously deformed into each other &lt;a href=&quot;https://en.wikipedia.org/wiki/Homology_(mathematics)#Construction_of_homology_groups&quot;&gt;1&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Connectivity information&lt;/strong&gt; is information concerning the loops and higher dimensional analogues in a space.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Functoriality&lt;/strong&gt; is the notion that invariants should be related not just to objects being studied, but also to the maps between those objects.&lt;/p&gt;

&lt;p&gt;Two mathematical objects are said to be &lt;strong&gt;homotopic&lt;/strong&gt; if one can be continuously deformed into the other.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;k-th Betti number&lt;/strong&gt; corresponds to an informal notion of the number of independent k-dimensional surfaces in a k-dimensional vector space.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;simplicial complex structure&lt;/strong&gt; on a space is an expression of the space as a union of points, intervals, triangles, and higher dimensional analogues.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;The homology of simplicial complexes is algorithmically computable; hence, it is desirable to construct a simplicial complex which computes the homology of an underlying space X. One way to do this is to produce a homotopy equivalence from X to the simplicial complex.&lt;/p&gt;

&lt;p&gt;Consider the case where there is a large amount of potentially noisy high-dimensional data. A question that can be asked is whether it is possible to infer the Betti numbers of the underlying space from the noisy data. The Cech complex &lt;a href=&quot;https://jeremykun.com/2015/08/06/cech-vietoris-rips-complex/&quot;&gt;2&lt;/a&gt; on a metric space, which is a covering by balls of a fixed radius $\epsilon$, is useful because it can be shown to be homotopy equivalent to the underlying Reimannian manifold. However, the data cannot be assumed to always lie on a manifold. The philosophy of selecting all values of $\epsilon$ at once to compute a summary of homological information is known as &lt;em&gt;persistence&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;interesting-points&quot;&gt;Interesting points&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;“Topology is exactly that branch of mathematics which deals with qualitative geometric information.”&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 20 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/paper-summaries/general-ml/2017/04/20/topology-data.html</link>
        <guid isPermaLink="true">http://localhost:4000/paper-summaries/general-ml/2017/04/20/topology-data.html</guid>
        
        
        <category>paper-summaries</category>
        
        <category>general-ML</category>
        
      </item>
    
  </channel>
</rss>
